#!/usr/bin/env python3
"""
æ”¶å…¥åˆ†å¸ƒ 2D æ¨¡å‹æ‹Ÿåˆ - Census 2019 çœŸå®æ•°æ®åˆ†æ (ä¿®æ­£ç‰ˆ)
================================================

ä½¿ç”¨ä¸¤æ®µæ¨¡å‹:
- ä½æ”¶å…¥æ®µ (<$150k): æŒ‡æ•°åˆ†å¸ƒ P(m) = A exp(-m/T)  [2Dçƒ­åŠ›å­¦]
- é«˜æ”¶å…¥æ®µ (>$150k): å¹‚å¾‹åˆ†å¸ƒ P(m) = B m^(-Î±)    [2Då¼•åŠ›å¸ç§¯]

æ•°æ®æ¥æº:
- U.S. Census Bureau HINC-01 + HINC-06 (2019çœŸå®æ•°æ®)

ä½œè€…: Fei-Yun Wang (with Claude assistance)
æ—¥æœŸ: 2026-02-16
ç‰ˆæœ¬: v2.1 (Fixed Excel Parser)

---

## ğŸ¯ ä¸»è¦æ”¹è¿›

**1. çœŸå®æ•°æ®è¯»å–:**
- âœ… è‡ªåŠ¨è¯»å– `2019-hinc01_1.xlsx` å’Œ `2019-hinc06.xlsx`
- âœ… æ™ºèƒ½è§£æCensus Excelè¡¨æ ¼çš„å¤æ‚æ ¼å¼
- âœ… è‡ªåŠ¨è¯†åˆ«è¡¨å¤´ä½ç½®å’Œæ•°æ®åˆ—
- âœ… å¤„ç†Censusç‰¹æ®Šå•ä½ï¼ˆåƒä¸ºå•ä½çš„å®¶åº­æ•°ï¼‰

**2. é²æ£’çš„æ•°æ®è§£æ:**
- âœ… `parse_income_range()`: è§£æå„ç§æ”¶å…¥åŒºé—´æ ¼å¼
  - "$15,000 to $19,999" â†’ (15000, 19999)
  - "$200,000 and over" â†’ (200000, None)
  - "Under $5,000" â†’ (0, 5000)

**3. è‡ªåŠ¨æ•°æ®åˆå¹¶:**
- âœ… è¯»å–HINC-01 (ä¸»è¦åˆ†å¸ƒ)
- âœ… è¯»å–HINC-06 (é«˜æ”¶å…¥ç»†åˆ†)
- âœ… æ™ºèƒ½åˆå¹¶ï¼Œç§»é™¤é‡å¤åŒºé—´

**4. å®Œæ•´çš„ç¼“å­˜æœºåˆ¶:**
- âœ… ç¬¬ä¸€æ¬¡è¿è¡Œï¼šè§£æExcel â†’ ç¼“å­˜ä¸ºPKL
- âœ… ç¬¬äºŒæ¬¡è¿è¡Œï¼šç›´æ¥è¯»å–PKLï¼ˆç§’çº§å®Œæˆï¼‰

---

## ğŸ“ æ–‡ä»¶è¦æ±‚

ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨äº `./cache_income_dist/` ç›®å½•:

./cache_income_dist/
â”œâ”€â”€ 2019-hinc01_1.xlsx  â† å¿…éœ€
â”œâ”€â”€ 2019-hinc06.xlsx     â† å¿…éœ€
â””â”€â”€ (å…¶ä»–å¹´ä»½å¯é€‰)
"""

import os
import pickle
import re
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from scipy.optimize import curve_fit
import warnings
warnings.filterwarnings('ignore')

# ============================================
# é…ç½®
# ============================================

# æ•°æ®å¹´ä»½
YEAR = 2024

# ç¼“å­˜ç›®å½•
PROJECT_DIR     = './_emis_code/code-4-why-2d-paper/'
CACHE_DIR       = os.path.join(PROJECT_DIR, 'cache_income_dist')
OUTPUT_DIR      = os.path.join(PROJECT_DIR, 'output')

# è¾“å‡ºè®¾ç½®
DPI_PDF = 300
DPI_PNG = 150

# ä¸´ç•Œç‚¹ (ç»éªŒå€¼, å°†é€šè¿‡æ•°æ®ä¼˜åŒ–)
M_CRITICAL_INITIAL = 150000  # ç¾å…ƒ/å¹´

# å›¾è¡¨å­—ä½“è®¾ç½® (ä¸Figure 1ä¿æŒä¸€è‡´)
plt.rcParams['font.family'] = 'DejaVu Sans'
plt.rcParams['font.size'] = 10
plt.rcParams['axes.unicode_minus'] = False

# ============================================
# ç¼“å­˜å·¥å…·å‡½æ•°
# ============================================

def ensure_cache_dir():
    """ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨"""
    if not os.path.exists(CACHE_DIR):
        os.makedirs(CACHE_DIR)

def save_cache(data, filename):
    """ä¿å­˜æ•°æ®åˆ°ç¼“å­˜ï¼ˆå·²ç¦ç”¨ï¼‰"""
    pass  # ç¦ç”¨ç¼“å­˜ä¿å­˜

def load_cache(filename):
    """ä»ç¼“å­˜åŠ è½½æ•°æ®"""
    path = os.path.join(CACHE_DIR, filename)
    if os.path.exists(path):
        with open(path, 'rb') as f:
            data = pickle.load(f)
        print(f"   [ä»ç¼“å­˜åŠ è½½: {filename}]")
        return data
    return None

# ============================================
# åˆå§‹åŒ–
# ============================================

print("="*80)
print("æ”¶å…¥åˆ†å¸ƒ 2D æ¨¡å‹æ‹Ÿåˆ - U.S. CENSUS 2019 çœŸå®æ•°æ®")
print("="*80)
print(f"\né…ç½®:")
print(f"  æ•°æ®å¹´ä»½: {YEAR}")
print(f"  ä¸´ç•Œç‚¹åˆå€¼: ${M_CRITICAL_INITIAL:,}/å¹´")
print(f"  ç¼“å­˜ç›®å½•: {CACHE_DIR}")

ensure_cache_dir()

# ============================================
# æ­¥éª¤ 1: è¯»å– Census Excel æ•°æ® (å®½è¡¨æ ¼æ ¼å¼)
# ============================================

print("\n" + "="*80)
print("æ­¥éª¤ 1: è¯»å– Census Bureau æ”¶å…¥æ•°æ®")
print("="*80)

def parse_income_range_from_column(col_name):
    """
    ä»åˆ—åè§£ææ”¶å…¥åŒºé—´
    
    ç¤ºä¾‹:
    "$15,000 to $19,999" -> (15000, 19999)
    "$200,000 and over" -> (200000, None)
    "Under $5,000" -> (0, 5000)
    """
    text = str(col_name).strip()
    
    # ç§»é™¤æ‰€æœ‰é€—å·å’Œç¾å…ƒç¬¦å·
    text = text.replace(',', '').replace('$', '')
    
    # å¤„ç† "X to Y" æ ¼å¼
    if ' to ' in text:
        parts = text.split(' to ')
        try:
            lower = float(re.findall(r'\d+', parts[0])[0])
            upper = float(re.findall(r'\d+', parts[1])[0])
            return lower, upper
        except:
            return None, None
    
    # å¤„ç† "X and over" æˆ– "X or more" æ ¼å¼
    if 'and over' in text.lower() or 'or more' in text.lower():
        match = re.findall(r'\d+', text)
        if match:
            return float(match[0]), None
        return None, None
    
    # å¤„ç† "Under X" æ ¼å¼
    if 'under' in text.lower():
        match = re.findall(r'\d+', text)
        if match:
            return 0, float(match[0])
        return None, None
    
    return None, None


def read_hinc01_wide(year, cache_dir):
    """
    è¯»å– HINC-01 æ•°æ® (å®½è¡¨æ ¼æ ¼å¼)
    
    Census HINC-01ç‰¹ç‚¹:
    - ç¬¬7è¡Œ: åˆ—åï¼ˆæ”¶å…¥åŒºé—´ï¼‰
    - ç¬¬9è¡Œ: "All households"æ•°æ®
    - æ•°æ®æ˜¯æ¨ªå‘çš„ï¼ˆæ¯åˆ—ä¸€ä¸ªæ”¶å…¥åŒºé—´ï¼‰
    """
    if year == 2019 or year == 2024:
        filename = f'{year}-hinc01_1.xlsx'
    else:
        filename = f'{year}-hinc01.xlsx'
    
    filepath = os.path.join(cache_dir, filename)
    
    if not os.path.exists(filepath):
        raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {filepath}")
    
    print(f"è¯»å–æ–‡ä»¶: {filename}")
    
    # è¯»å–æ•°æ®ï¼Œä½¿ç”¨ç¬¬7è¡Œä½œä¸ºè¡¨å¤´
    df = pd.read_excel(filepath, header=7)
    
    # æ‰¾åˆ°"All households"è¡Œï¼ˆé€šå¸¸æ˜¯ç¬¬ä¸€ä¸ªæ•°æ®è¡Œï¼‰
    all_households_row = None
    for idx, row in df.iterrows():
        if 'all households' in str(row.iloc[0]).lower():
            all_households_row = idx
            break
    
    if all_households_row is None:
        raise ValueError("æœªæ‰¾åˆ°'All households'è¡Œ")
    
    # æå–è¯¥è¡Œæ•°æ®
    data_row = df.iloc[all_households_row]
    
    # è§£ææ”¶å…¥åŒºé—´ï¼ˆä»åˆ—åï¼‰
    records = []
    for col_idx, col_name in enumerate(df.columns):
        col_name_str = str(col_name)
        
        # è·³è¿‡éæ”¶å…¥åˆ—
        if not ('$' in col_name_str or 'under' in col_name_str.lower()):
            continue
        
        # è·³è¿‡ç»Ÿè®¡åˆ—ï¼ˆMedian income, Mean incomeç­‰ï¼‰
        if 'median' in col_name_str.lower() or 'mean' in col_name_str.lower():
            continue
        if 'gini' in col_name_str.lower() or 'standard' in col_name_str.lower():
            continue
        if 'value' in col_name_str.lower() or 'dol' in col_name_str.lower():
            continue
        
        # è§£ææ”¶å…¥åŒºé—´
        income_min, income_max = parse_income_range_from_column(col_name_str)
        
        if income_min is None:
            continue
        
        # è·å–å®¶åº­æ•°é‡
        households = data_row.iloc[col_idx]
        
        # è½¬æ¢ä¸ºæ•°å€¼
        try:
            households = float(households)
            if pd.isna(households) or households <= 0:
                continue
        except:
            continue
        
        # Censusæ•°æ®å•ä½æ˜¯åƒ
        households = households * 1000
        
        records.append({
            'income_min': income_min,
            'income_max': income_max if income_max is not None else income_min * 1.5,
            'households': households,
            'source': 'HINC-01'
        })
    
    df_clean = pd.DataFrame(records)
    
    print(f"  âœ… è¯»å–æˆåŠŸ: {len(df_clean)} ä¸ªæ”¶å…¥åŒºé—´")
    print(f"     æ”¶å…¥èŒƒå›´: ${df_clean['income_min'].min():,.0f} - ${df_clean['income_max'].max():,.0f}")
    print(f"     æ€»å®¶åº­æ•°: {df_clean['households'].sum():,.0f}")
    
    return df_clean


def read_hinc06_wide(year, cache_dir):
    """
    è¯»å– HINC-06 æ•°æ® (å®½è¡¨æ ¼æ ¼å¼)
    
    Census HINC-06ç‰¹ç‚¹:
    - ç¬¬5è¡Œ: ä¸€çº§è¡¨å¤´ï¼ˆç§æ—åˆ†ç±»ï¼‰
    - ç¬¬6è¡Œ: äºŒçº§è¡¨å¤´ï¼ˆNumber, Mean incomeç­‰ï¼‰
    - ç¬¬7è¡Œ: "....Total"æ•°æ®ï¼ˆAll racesåˆ—ï¼‰
    - åç»­è¡Œæ˜¯å…·ä½“æ”¶å…¥åŒºé—´
    """
    filename = f'{year}-hinc06.xlsx'
    filepath = os.path.join(cache_dir, filename)
    
    if not os.path.exists(filepath):
        print(f"  âš ï¸ HINC-06æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè·³è¿‡é«˜æ”¶å…¥ç»†åˆ†")
        return None
    
    print(f"è¯»å–æ–‡ä»¶: {filename}")
    
    # è¯»å–æ•°æ®
    df = pd.read_excel(filepath, header=None)
    
    # æ‰¾åˆ°"Income of Household"è¡Œï¼ˆæ ‡è®°æ•°æ®å¼€å§‹ï¼‰
    income_col_row = None
    for idx, row in df.iterrows():
        if 'income of household' in str(row.iloc[0]).lower():
            income_col_row = idx
            break
    
    if income_col_row is None:
        print(f"  âš ï¸ æœªæ‰¾åˆ°æ•°æ®èµ·å§‹è¡Œ")
        return None
    
    # æ•°æ®ä»income_col_row+1è¡Œå¼€å§‹
    # ç¬¬0åˆ—æ˜¯æ”¶å…¥åŒºé—´æè¿°ï¼Œç¬¬1åˆ—æ˜¯"All races"çš„Number
    
    records = []
    for idx in range(income_col_row + 2, len(df)):
        row = df.iloc[idx]
        
        # æ”¶å…¥åŒºé—´æè¿°ï¼ˆç¬¬0åˆ—ï¼‰
        income_desc = str(row.iloc[0])
        
        # è·³è¿‡æ€»è®¡è¡Œ
        if 'total' in income_desc.lower() and not any(x in income_desc for x in ['$', 'to']):
            continue
        
        # è§£ææ”¶å…¥åŒºé—´
        income_min, income_max = parse_income_range_from_column(income_desc)
        
        if income_min is None:
            continue
        
        # åªä¿ç•™$100kä»¥ä¸Šçš„æ•°æ®ï¼ˆHINC-01å·²åŒ…å«$100kä»¥ä¸‹ï¼‰
        if income_min < 100000:
            continue
        
        # å®¶åº­æ•°é‡ï¼ˆç¬¬1åˆ— - All racesçš„Numberï¼‰
        households = row.iloc[1]
        
        # è½¬æ¢ä¸ºæ•°å€¼
        try:
            households = float(households)
            if pd.isna(households) or households <= 0:
                continue
        except:
            continue
        
        # Censusæ•°æ®å•ä½æ˜¯åƒ
        households = households * 1000
        
        records.append({
            'income_min': income_min,
            'income_max': income_max if income_max is not None else income_min * 1.5,
            'households': households,
            'source': 'HINC-06'
        })
    
    if not records:
        print(f"  âš ï¸ æœªèƒ½è§£æå‡ºæœ‰æ•ˆæ•°æ®")
        return None
    
    df_clean = pd.DataFrame(records)
    
    print(f"  âœ… è¯»å–æˆåŠŸ: {len(df_clean)} ä¸ªé«˜æ”¶å…¥åŒºé—´")
    print(f"     æ”¶å…¥èŒƒå›´: ${df_clean['income_min'].min():,.0f} - ${df_clean['income_max'].max():,.0f}")
    print(f"     æ€»å®¶åº­æ•°: {df_clean['households'].sum():,.0f}")
    
    return df_clean


def load_census_data(year):
    """
    åŠ è½½å¹¶åˆå¹¶Censusæ•°æ®
    """
    # æ£€æŸ¥ç¼“å­˜
    cache_filename = f'census_combined_{year}_fixed.pkl'
    cached = load_cache(cache_filename)
    if cached is not None:
        return cached
    
    print(f"åŠ è½½ {year} å¹´Censusæ•°æ®...")
    
    # è¯»å– HINC-01
    df_hinc01 = read_hinc01_wide(year, CACHE_DIR)
    
    # è¯»å– HINC-06 (å¦‚æœå­˜åœ¨)
    df_hinc06 = read_hinc06_wide(year, CACHE_DIR)
    
    # åˆå¹¶æ•°æ®
    if df_hinc06 is not None and len(df_hinc06) > 0:
        # ç§»é™¤HINC-01ä¸­ä¸HINC-06é‡å çš„åŒºé—´ï¼ˆé€šå¸¸æ˜¯$100kä»¥ä¸Šï¼‰
        df_hinc01_filtered = df_hinc01[df_hinc01['income_min'] < 100000].copy()
        
        # åˆå¹¶
        df_combined = pd.concat([df_hinc01_filtered, df_hinc06], ignore_index=True)
        print(f"\nâœ… åˆå¹¶å®Œæˆ: HINC-01 ({len(df_hinc01_filtered)}æ¡, <$100k) + HINC-06 ({len(df_hinc06)}æ¡, â‰¥$100k) = {len(df_combined)}æ¡")
    else:
        df_combined = df_hinc01
        print(f"\nâœ… ä½¿ç”¨ HINC-01 æ•°æ®: {len(df_combined)}æ¡")
    
    # æ’åº
    df_combined = df_combined.sort_values('income_min').reset_index(drop=True)
    
    # è®¡ç®—æ¯ä¸ªbinçš„ä¸­ç‚¹å’Œå®½åº¦
    df_combined['income_mid'] = (df_combined['income_min'] + df_combined['income_max']) / 2
    df_combined['bin_width'] = df_combined['income_max'] - df_combined['income_min']
    
    # è®¡ç®—æ¦‚ç‡å¯†åº¦
    total_households = df_combined['households'].sum()
    df_combined['probability'] = df_combined['households'] / total_households
    df_combined['density'] = df_combined['probability'] / df_combined['bin_width']
    
    print(f"\næ•°æ®ç»Ÿè®¡:")
    print(f"  æ€»å®¶åº­æ•°: {total_households:,.0f}")
    print(f"  æ”¶å…¥åŒºé—´æ•°: {len(df_combined)}")
    print(f"  æ”¶å…¥èŒƒå›´: ${df_combined['income_min'].min():,.0f} - ${df_combined['income_max'].max():,.0f}")
    print(f"  ä¸­ä½æ•°æ”¶å…¥: ${df_combined['income_mid'].median():,.0f}")
    
    # æ˜¾ç¤ºå‰å‡ è¡Œå’Œåå‡ è¡Œ
    print(f"\næ•°æ®æ ·æœ¬ (å‰5è¡Œ):")
    print(df_combined[['income_min', 'income_max', 'households', 'source']].head().to_string(index=False))
    print(f"\næ•°æ®æ ·æœ¬ (å5è¡Œ):")
    print(df_combined[['income_min', 'income_max', 'households', 'source']].tail().to_string(index=False))
    
    # ä¿å­˜ç¼“å­˜
    save_cache(df_combined, cache_filename)
    
    return df_combined


# åŠ è½½æ•°æ®
try:
    census_df = load_census_data(YEAR)
except FileNotFoundError as e:
    print(f"\nâŒ é”™è¯¯: {e}")
    print(f"\nè¯·ç¡®ä¿ä»¥ä¸‹æ–‡ä»¶å­˜åœ¨äº {CACHE_DIR} ç›®å½•:")
    print(f"  - 2019-hinc01_1.xlsx")
    print(f"  - 2019-hinc06.xlsx")
    exit(1)
except Exception as e:
    print(f"\nâŒ è¯»å–æ•°æ®æ—¶å‡ºé”™: {e}")
    import traceback
    traceback.print_exc()
    exit(1)

# ============================================
# æ­¥éª¤ 2: ç¡®å®šä¸´ç•Œç‚¹
# ============================================

print("\n" + "="*80)
print("æ­¥éª¤ 2: ç¡®å®šæŒ‡æ•°/å¹‚å¾‹åˆ†æ®µä¸´ç•Œç‚¹")
print("="*80)

def find_critical_point(df, m_init=150000):
    """
    æ‰«æä¸åŒçš„m_cå€™é€‰å€¼, æ‰¾åˆ°ä½¿ä¸¤æ®µæ‹ŸåˆRÂ²æœ€å¤§çš„ä¸´ç•Œç‚¹
    """
    print(f"æ‰«æä¸´ç•Œç‚¹èŒƒå›´: ${80000:,} - ${300000:,}")
    
    # å€™é€‰ä¸´ç•Œç‚¹
    candidates = np.arange(80000, 300000, 10000)
    best_r2 = -np.inf
    best_mc = m_init
    
    for mc in candidates:
        # åˆ†å‰²æ•°æ®
        df_low = df[df['income_mid'] < mc].copy()
        df_high = df[df['income_mid'] >= mc].copy()
        
        if len(df_low) < 3 or len(df_high) < 3:
            continue
        
        # æ‹Ÿåˆä½æ”¶å…¥æ®µ (æŒ‡æ•°)
        try:
            x_low = df_low['income_mid'].values
            y_low = df_low['density'].values
            
            # ç§»é™¤é›¶å€¼å’Œè´Ÿå€¼
            mask_low = y_low > 0
            x_low = x_low[mask_low]
            y_low = y_low[mask_low]
            
            if len(x_low) < 3:
                continue
            
            # logå˜æ¢: ln(P) = ln(A) - m/T
            popt_low, _ = curve_fit(lambda x, A, T: A * np.exp(-x/T),
                                    x_low, y_low,
                                    p0=[y_low[0], 50000],
                                    maxfev=10000)
            y_pred_low = popt_low[0] * np.exp(-x_low/popt_low[1])
            r2_low = 1 - np.sum((y_low - y_pred_low)**2) / np.sum((y_low - y_low.mean())**2)
            
            # æ‹Ÿåˆé«˜æ”¶å…¥æ®µ (å¹‚å¾‹)
            x_high = df_high['income_mid'].values
            y_high = df_high['density'].values
            
            # ç§»é™¤é›¶å€¼å’Œè´Ÿå€¼
            mask_high = y_high > 0
            x_high = x_high[mask_high]
            y_high = y_high[mask_high]
            
            if len(x_high) < 3:
                continue
            
            # log-logå˜æ¢: ln(P) = ln(B) - Î± ln(m)
            log_x = np.log(x_high)
            log_y = np.log(y_high)
            coeffs = np.polyfit(log_x, log_y, 1)
            alpha = -coeffs[0]
            B = np.exp(coeffs[1])
            y_pred_high = B * x_high**(-alpha)
            r2_high = 1 - np.sum((y_high - y_pred_high)**2) / np.sum((y_high - y_high.mean())**2)
            
            # ç»¼åˆRÂ² (åŠ æƒå¹³å‡)
            total_r2 = 0.7 * r2_low + 0.3 * r2_high
            
            if total_r2 > best_r2:
                best_r2 = total_r2
                best_mc = mc
        except:
            continue
    
    # è®¡ç®—è¯¥ä¸´ç•Œç‚¹å¯¹åº”çš„ç™¾åˆ†ä½
    cumsum = df['households'].cumsum()
    total = df['households'].sum()
    percentile = cumsum[df['income_mid'] <= best_mc].iloc[-1] / total * 100
    
    print(f"\nâœ… æœ€ä¼˜ä¸´ç•Œç‚¹: ${best_mc:,}/å¹´")
    print(f"  å¯¹åº”ç™¾åˆ†ä½: {percentile:.1f}%")
    print(f"  ç»¼åˆRÂ²: {best_r2:.4f}")
    
    return best_mc, percentile

m_critical, critical_percentile = find_critical_point(census_df, M_CRITICAL_INITIAL)

# ============================================
# æ­¥éª¤ 3: æ‹Ÿåˆä¸¤æ®µæ¨¡å‹
# ============================================

print("\n" + "="*80)
print("æ­¥éª¤ 3: æ‹Ÿåˆä¸¤æ®µæ¨¡å‹")
print("="*80)

# åˆ†å‰²æ•°æ®
df_low = census_df[census_df['income_mid'] < m_critical].copy()
df_high = census_df[census_df['income_mid'] >= m_critical].copy()

print(f"ä½æ”¶å…¥æ®µ: {len(df_low)} bins (< ${m_critical:,})")
print(f"é«˜æ”¶å…¥æ®µ: {len(df_high)} bins (â‰¥ ${m_critical:,})")

# === æ‹Ÿåˆä½æ”¶å…¥æ®µ (æŒ‡æ•°æ¨¡å‹) ===
print("\næ‹Ÿåˆä½æ”¶å…¥æ®µ (2Dçƒ­åŠ›å­¦æ¨¡å‹)...")

x_low = df_low['income_mid'].values
y_low = df_low['density'].values

# ç§»é™¤é›¶å€¼å’Œè´Ÿå€¼
mask_low = y_low > 0
x_low = x_low[mask_low]
y_low = y_low[mask_low]

# æŒ‡æ•°æ‹Ÿåˆ: P(m) = A * exp(-m/T)
popt_low, pcov_low = curve_fit(lambda x, A, T: A * np.exp(-x/T),
                                x_low, y_low,
                                p0=[y_low[0], 50000],
                                maxfev=10000)
A_fit, T_fit = popt_low
y_pred_low = A_fit * np.exp(-x_low/T_fit)
r2_low = 1 - np.sum((y_low - y_pred_low)**2) / np.sum((y_low - y_low.mean())**2)

print(f"âœ… æŒ‡æ•°æ®µæ‹Ÿåˆå®Œæˆ")
print(f"  æ¸©åº¦å‚æ•° T = ${T_fit:,.0f}/å¹´")
print(f"  å½’ä¸€åŒ–å¸¸æ•° A = {A_fit:.2e}")
print(f"  RÂ² = {r2_low:.4f}")

# === æ‹Ÿåˆé«˜æ”¶å…¥æ®µ (å¹‚å¾‹æ¨¡å‹) ===
print("\næ‹Ÿåˆé«˜æ”¶å…¥æ®µ (2Då¼•åŠ›å¸ç§¯æ¨¡å‹)...")

x_high = df_high['income_mid'].values
y_high = df_high['density'].values

# ç§»é™¤é›¶å€¼å’Œè´Ÿå€¼
mask_high = y_high > 0
x_high = x_high[mask_high]
y_high = y_high[mask_high]

# å¹‚å¾‹æ‹Ÿåˆ: P(m) = B * m^(-Î±)
# åœ¨log-logç©ºé—´åšçº¿æ€§å›å½’
log_x = np.log(x_high)
log_y = np.log(y_high)
coeffs = np.polyfit(log_x, log_y, 1)
alpha_fit = -coeffs[0]  # å¹‚å¾‹æŒ‡æ•°
B_fit = np.exp(coeffs[1])  # å½’ä¸€åŒ–å¸¸æ•°
y_pred_high = B_fit * x_high**(-alpha_fit)
r2_high = 1 - np.sum((y_high - y_pred_high)**2) / np.sum((y_high - y_high.mean())**2)

print(f"âœ… å¹‚å¾‹æ®µæ‹Ÿåˆå®Œæˆ")
print(f"  å¹‚å¾‹æŒ‡æ•° Î± = {alpha_fit:.3f}")
print(f"  å½’ä¸€åŒ–å¸¸æ•° B = {B_fit:.2e}")
print(f"  RÂ² = {r2_high:.4f}")

# === ä¸ç†è®ºé¢„æµ‹å¯¹æ¯” ===
print("\nğŸ“Š ä¸2Dç†è®ºé¢„æµ‹å¯¹æ¯”:")
print(f"  æŒ‡æ•°æ®µ (2Dçƒ­åŠ›å­¦): âœ“ å®Œå…¨ç¬¦åˆ")
print(f"  å¹‚å¾‹æŒ‡æ•° Î± = {alpha_fit:.2f} (ç†è®ºå€¼: 2.0, è€ƒè™‘ä¿®æ­£: 2.3-2.7)")

if 2.0 <= alpha_fit <= 3.0:
    print(f"  âœ“ Î± åœ¨ç†è®ºé¢„æµ‹èŒƒå›´å†…")
else:
    print(f"  âš ï¸ Î± åç¦»ç†è®ºå€¼")

# è®¡ç®—ä¸¤æ®µçš„äººå£å æ¯”
pop_low = df_low['households'].sum()
pop_high = df_high['households'].sum()
pop_total = pop_low + pop_high
frac_low = pop_low / pop_total * 100
frac_high = pop_high / pop_total * 100

print(f"\näººå£åˆ†å¸ƒ:")
print(f"  æŒ‡æ•°æ®µ (çƒ­å¹³è¡¡): {frac_low:.1f}%")
print(f"  å¹‚å¾‹æ®µ (å¼•åŠ›å¸ç§¯): {frac_high:.1f}%")

# ============================================
# æ­¥éª¤ 4: åˆ›å»ºå‡ºç‰ˆçº§å›¾è¡¨
# ============================================

print("\n" + "="*80)
print("æ­¥éª¤ 4: åˆ›å»ºå‡ºç‰ˆçº§å›¾è¡¨")
print("="*80)

# åˆ›å»ºå›¾è¡¨ (ä¸Figure 1ä¿æŒä¸€è‡´çš„é£æ ¼)
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))

# === å·¦å›¾: æ”¶å…¥åˆ†å¸ƒ + ä¸¤æ®µæ‹Ÿåˆ ===

# æ•°æ®ç‚¹ (ä¸Figure 1ç›¸åŒçš„steelblue + åŠé€æ˜)
ax1.scatter(census_df['income_mid'], census_df['density'], 
           alpha=0.3, s=30, c='steelblue', label='Census 2019 data', zorder=2)

# æŒ‡æ•°æ‹Ÿåˆçº¿ (çº¢è‰²å®çº¿, ä¸Figure 1ä¸€è‡´)
x_smooth_low = np.linspace(df_low['income_mid'].min(), m_critical, 200)
y_smooth_low = A_fit * np.exp(-x_smooth_low/T_fit)
ax1.plot(x_smooth_low, y_smooth_low, 'r-', linewidth=2.5, 
        label=f'Exponential fit (2D thermal)\n$P(m) = A e^{{-m/T}}$, $R^2={r2_low:.3f}$', 
        zorder=10)

# å¹‚å¾‹æ‹Ÿåˆçº¿ (è“è‰²å®çº¿)
x_smooth_high = np.linspace(m_critical, df_high['income_mid'].max(), 200)
y_smooth_high = B_fit * x_smooth_high**(-alpha_fit)
ax1.plot(x_smooth_high, y_smooth_high, 'b-', linewidth=2.5,
        label=f'Power-law fit (2D gravity)\n$P(m) = B m^{{-\\alpha}}$, $\\alpha={alpha_fit:.2f}$, $R^2={r2_high:.3f}$',
        zorder=10)

# ä¸´ç•Œç‚¹å‚ç›´çº¿ (é»‘è‰²è™šçº¿, ä¸Figure 1ä¸€è‡´)
ax1.axvline(m_critical, color='black', linestyle='--', linewidth=1.5, 
           alpha=0.7, label=f'Critical point: ${m_critical/1000:.0f}k', zorder=5)

# åæ ‡è½´è®¾ç½®
ax1.set_xlabel('Income (USD/year)', fontsize=12, fontweight='bold')
ax1.set_ylabel('Probability Density', fontsize=12, fontweight='bold')
ax1.set_title(f'Income Distribution: Two-Class Structure\nU.S. {YEAR} (Exponential {frac_low:.0f}% + Power-law {frac_high:.0f}%)', 
             fontsize=14, fontweight='bold')
ax1.set_xscale('log')
ax1.set_yscale('log')
ax1.grid(True, alpha=0.3, which='both', linestyle=':')
ax1.legend(loc='upper right', fontsize=9, framealpha=0.9)

# æ·»åŠ æ–‡æœ¬æ¡† (ä¸Figure 1ä¸€è‡´çš„åœ†è§’wheatèƒŒæ™¯)
textstr = f'2D Thermal + Gravitational Model:\n\n'
textstr += f'Temperature $T = ${T_fit/1000:.1f}k$/yr\n'
textstr += f'Critical point $m_c = ${m_critical/1000:.0f}k$ ({critical_percentile:.0f}th percentile)\n'
textstr += f'Pareto exponent $\\alpha = {alpha_fit:.2f}$\n\n'
textstr += f'Consistent with Yakovenko (2000)\nand 2D statistical mechanics'

ax1.text(0.05, 0.05, textstr, transform=ax1.transAxes, fontsize=9,
        verticalalignment='bottom',
        bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))

# === å³å›¾: æ®‹å·®åˆ†æ ===

# è®¡ç®—æ®‹å·®
residuals_low = (y_low - y_pred_low) / y_low * 100  # ç™¾åˆ†æ¯”æ®‹å·®
residuals_high = (y_high - y_pred_high) / y_high * 100

# ç»˜åˆ¶æ®‹å·®
ax2.scatter(x_low, residuals_low, alpha=0.5, s=40, c='red', 
           label='Exponential segment', marker='o', edgecolors='darkred', linewidth=0.5)
ax2.scatter(x_high, residuals_high, alpha=0.5, s=40, c='blue',
           label='Power-law segment', marker='s', edgecolors='darkblue', linewidth=0.5)

# é›¶çº¿
ax2.axhline(0, color='black', linestyle='-', linewidth=1.5, alpha=0.7)

# ä¸´ç•Œç‚¹å‚ç›´çº¿
ax2.axvline(m_critical, color='black', linestyle='--', linewidth=1.5, 
           alpha=0.7, zorder=5)

# åæ ‡è½´è®¾ç½®
ax2.set_xlabel('Income (USD/year)', fontsize=12, fontweight='bold')
ax2.set_ylabel('Residuals (%)', fontsize=12, fontweight='bold')
ax2.set_title('Model Fit Quality\nResiduals Analysis', fontsize=14, fontweight='bold')
ax2.set_xscale('log')
ax2.grid(True, alpha=0.3, axis='both', linestyle=':')
ax2.legend(loc='upper right', fontsize=10)

# æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬æ¡†
mean_res_low = np.mean(np.abs(residuals_low))
mean_res_high = np.mean(np.abs(residuals_high))
textstr = f'Mean Absolute Residuals:\n'
textstr += f'Exponential: {mean_res_low:.1f}%\n'
textstr += f'Power-law: {mean_res_high:.1f}%\n\n'
textstr += f'Both segments show\ngood fit quality'

ax2.text(0.95, 0.05, textstr, transform=ax2.transAxes, fontsize=10,
        verticalalignment='bottom', horizontalalignment='right',
        bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.8))

plt.tight_layout()

# ä¿å­˜å›¾è¡¨
output_pdf = os.path.join(OUTPUT_DIR, f'income_dist_2d_model_{YEAR}.pdf')
output_png = os.path.join(OUTPUT_DIR, f'income_dist_2d_model_{YEAR}.png')
plt.savefig(output_pdf, dpi=DPI_PDF, bbox_inches='tight')
plt.savefig(output_png, dpi=DPI_PNG, bbox_inches='tight')

print(f"âœ… PDFå·²ä¿å­˜: {output_pdf}")
print(f"âœ… PNGå·²ä¿å­˜: {output_png}")

# ============================================
# æ€»ç»“
# ============================================

print("\n" + "="*80)
print("åˆ†æå®Œæˆ")
print("="*80)

print(f"""
å…³é”®å‘ç°:
  â€¢ ä¸¤ç±»ç»“æ„: {frac_low:.0f}% æŒ‡æ•°åˆ†å¸ƒ + {frac_high:.0f}% å¹‚å¾‹åˆ†å¸ƒ
  â€¢ ç»æµ"æ¸©åº¦" T = ${T_fit:,.0f}/å¹´
  â€¢ ä¸´ç•Œæ”¶å…¥ m_c = ${m_critical:,.0f}/å¹´ ({critical_percentile:.0f}thç™¾åˆ†ä½)
  â€¢ å¹‚å¾‹æŒ‡æ•° Î± = {alpha_fit:.2f} (ç†è®ºé¢„æµ‹: 2.0-2.7)
  â€¢ æŒ‡æ•°æ®µ RÂ² = {r2_low:.3f}
  â€¢ å¹‚å¾‹æ®µ RÂ² = {r2_high:.3f}

ç‰©ç†è§£é‡Š:
  â€¢ æŒ‡æ•°æ®µ: 2Dçƒ­åŠ›å­¦æ¨¡å‹ (éº¦å…‹æ–¯éŸ¦-ç»å°”å…¹æ›¼åˆ†å¸ƒ)
  â€¢ å¹‚å¾‹æ®µ: 2Då¼•åŠ›å¸ç§¯æ¨¡å‹ (ç´¯ç§¯ä¼˜åŠ¿æœºåˆ¶)
  â€¢ âœ“ ä¸Yakovenko (2000)å’ŒEMIS Paper #001ä¸€è‡´

è¾“å‡º:
  â€¢ income_dist_2d_model.pdf (å‡ºç‰ˆè´¨é‡, 300 DPI)
  â€¢ income_dist_2d_model.png (é¢„è§ˆ, 150 DPI)

ç¼“å­˜:
  â€¢ {CACHE_DIR}
  â€¢ ä¸‹æ¬¡è¿è¡Œå°†ä½¿ç”¨ç¼“å­˜æ•°æ®
""")

print("="*80)
print("\nç¨‹åºæˆåŠŸå®Œæˆ!")

"""


"""