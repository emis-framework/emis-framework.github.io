"""
ä¿®å¤å¾·å›½ DAX éªŒè¯ï¼ˆå¸¦æœ¬åœ°ç¼“å­˜ï¼‰
"""

import numpy as np
import pandas as pd
import yfinance as yf
import time
import os
import warnings
warnings.filterwarnings('ignore')

# ============================================
# å‚æ•°è®¾ç½®
# ============================================

START_DATE = '2005-01-01'
TRAIN_END = '2020-01-01'
WINDOW = 60
HORIZON = 30

# æ›´æ–°çš„å¾·å›½è‚¡ç¥¨åˆ—è¡¨
DAX_TICKERS = [
    'SAP.DE',      # SAP
    'SIE.DE',      # Siemens
    'ALV.DE',      # Allianz
    'DTE.DE',      # Deutsche Telekom
    'BAS.DE',      # BASF
    'BAYN.DE',     # Bayer
    'MBG.DE',      # Mercedes-Benz
    'BMW.DE',      # BMW
    'MUV2.DE',     # Munich Re
    'ADS.DE',      # Adidas
    'VOW3.DE',     # Volkswagen
    'IFX.DE',      # Infineon
    'HEN3.DE',     # Henkel
    'RWE.DE',      # RWE
    'EOAN.DE',     # E.ON
    'DBK.DE',      # Deutsche Bank
    'DHL.DE',      # Deutsche Post
    'CON.DE',      # Continental
    'BEI.DE',      # Beiersdorf
    'HEI.DE',      # HeidelbergCement
    'FRE.DE',      # Fresenius
    'LIN.DE',      # Linde
    'PAH3.DE',     # Porsche
    'SHL.DE',      # Siemens Healthineers
    'QIA.DE',      # QIAGEN
]

# ç¼“å­˜æ–‡ä»¶å
STOCK_CACHE = 'stocks_DAX.csv'
INDEX_CACHE = 'index_DAX.csv'
ENTROPY_CACHE = 'entropy_DAX.csv'

# ============================================
# æ•°æ®åŠ è½½å‡½æ•°
# ============================================

def load_stock_data():
    """åŠ è½½è‚¡ç¥¨æ•°æ®ï¼ˆä¼˜å…ˆæœ¬åœ°ï¼‰"""
    
    if os.path.exists(STOCK_CACHE):
        print(f"ä»æœ¬åœ°åŠ è½½: {STOCK_CACHE}")
        prices = pd.read_csv(STOCK_CACHE, index_col=0, parse_dates=True)
        print(f"åŠ è½½æˆåŠŸ: {len(prices.columns)} åªè‚¡ç¥¨, {len(prices)} å¤©")
        return prices
    
    print("æœ¬åœ°æ— ç¼“å­˜ï¼Œå¼€å§‹ä¸‹è½½...")
    all_data = []
    
    for i in range(0, len(DAX_TICKERS), 5):
        batch = DAX_TICKERS[i:i+5]
        print(f"  ä¸‹è½½ {i+1}-{min(i+5, len(DAX_TICKERS))}/{len(DAX_TICKERS)}: {batch}")
        
        try:
            data = yf.download(batch, start=START_DATE, progress=False)
            if not data.empty:
                if isinstance(data.columns, pd.MultiIndex):
                    all_data.append(data['Close'])
                else:
                    all_data.append(data['Close'])
            time.sleep(1)
        except Exception as e:
            print(f"    é”™è¯¯: {e}")
            time.sleep(3)
    
    if not all_data:
        print("âŒ ä¸‹è½½å¤±è´¥")
        return None
    
    prices = pd.concat(all_data, axis=1)
    prices.to_csv(STOCK_CACHE)
    print(f"å·²ä¿å­˜: {STOCK_CACHE}")
    
    return prices

def load_index_data():
    """åŠ è½½æŒ‡æ•°æ•°æ®ï¼ˆä¼˜å…ˆæœ¬åœ°ï¼‰"""
    
    if os.path.exists(INDEX_CACHE):
        print(f"ä»æœ¬åœ°åŠ è½½: {INDEX_CACHE}")
        index = pd.read_csv(INDEX_CACHE, index_col=0, parse_dates=True).iloc[:, 0]
        print(f"åŠ è½½æˆåŠŸ: {len(index)} å¤©")
        return index
    
    print("ä¸‹è½½ DAX æŒ‡æ•°...")
    time.sleep(2)
    
    try:
        data = yf.download('^GDAXI', start=START_DATE, progress=False)
        if data.empty:
            print("âŒ ä¸‹è½½å¤±è´¥")
            return None
        
        index = data['Close']
        if isinstance(index, pd.DataFrame):
            index = index.iloc[:, 0]
        
        index.to_csv(INDEX_CACHE)
        print(f"å·²ä¿å­˜: {INDEX_CACHE}")
        return index
        
    except Exception as e:
        print(f"é”™è¯¯: {e}")
        return None

# ============================================
# è®¡ç®—å‡½æ•°
# ============================================

def compute_returns(prices):
    return np.log(prices / prices.shift(1)).dropna()

def compute_entanglement_entropy(returns, window=60):
    """è®¡ç®—çº ç¼ ç†µ"""
    S_list = []
    dates = []
    N = returns.shape[1]
    
    for t in range(window, len(returns)):
        window_returns = returns.iloc[t-window:t]
        Sigma = window_returns.corr().values
        Sigma = Sigma + np.eye(N) * 1e-6
        det_Sigma = np.linalg.det(Sigma)
        
        if det_Sigma > 0:
            S = -np.log(det_Sigma) / N
        else:
            S = np.nan
        
        S_list.append(S)
        dates.append(returns.index[t])
    
    return pd.Series(S_list, index=dates, name='S')

def test_strategy(S, index, threshold, horizon=30):
    """æµ‹è¯•ç­–ç•¥"""
    results = []
    
    for t in range(len(S) - horizon):
        date = S.index[t]
        value = S.iloc[t]
        
        if value > threshold and date in index.index:
            idx = index.index.get_loc(date)
            if idx + horizon < len(index):
                ret = np.log(index.iloc[idx + horizon] / index.iloc[idx])
                results.append({
                    'date': date,
                    'S': value,
                    'return': ret,
                    'win': ret > 0
                })
    
    return pd.DataFrame(results) if results else None

# ============================================
# ä¸»ç¨‹åº
# ============================================

def main():
    print("="*60)
    print("å¾·å›½ DAX å¸‚åœºéªŒè¯ï¼ˆä¿®å¤ç‰ˆï¼‰")
    print("="*60)
    print(f"æ•°æ®èµ·å§‹: {START_DATE}")
    print(f"è®­ç»ƒæˆªæ­¢: {TRAIN_END}")
    print("="*60)
    
    # 1. åŠ è½½è‚¡ç¥¨æ•°æ®
    prices = load_stock_data()
    if prices is None:
        return None
    
    # æ¸…ç†æ•°æ®
    prices = prices.dropna(axis=1, how='all').ffill().dropna()
    print(f"\næœ‰æ•ˆæ•°æ®: {len(prices.columns)} åªè‚¡ç¥¨")
    print(f"æ—¶é—´èŒƒå›´: {prices.index.min().date()} - {prices.index.max().date()}")
    print(f"æ€»å¤©æ•°: {len(prices)}")
    
    # 2. åŠ è½½æŒ‡æ•°æ•°æ®
    index = load_index_data()
    if index is None:
        return None
    
    # 3. è®¡ç®—çº ç¼ ç†µ
    if os.path.exists(ENTROPY_CACHE):
        print(f"\nä»æœ¬åœ°åŠ è½½çº ç¼ ç†µ: {ENTROPY_CACHE}")
        S = pd.read_csv(ENTROPY_CACHE, index_col=0, parse_dates=True).iloc[:, 0]
    else:
        print("\nè®¡ç®—çº ç¼ ç†µ...")
        returns = compute_returns(prices)
        S = compute_entanglement_entropy(returns, WINDOW)
        S.to_csv(ENTROPY_CACHE)
        print(f"å·²ä¿å­˜: {ENTROPY_CACHE}")
    
    print(f"çº ç¼ ç†µèŒƒå›´: [{S.min():.2f}, {S.max():.2f}]")
    print(f"å‡å€¼: {S.mean():.2f}, æ ‡å‡†å·®: {S.std():.2f}")
    
    # 4. å¯¹é½æ—¶é—´
    common_idx = S.index.intersection(index.index)
    S = S.loc[common_idx]
    index = index.loc[common_idx]
    
    print(f"\nå¯¹é½åæ•°æ®: {len(common_idx)} å¤©")
    
    # 5. æ ·æœ¬åˆ’åˆ†
    train_mask = S.index < TRAIN_END
    test_mask = S.index >= TRAIN_END
    
    S_train = S[train_mask]
    S_test = S[test_mask]
    index_train = index[train_mask]
    index_test = index[test_mask]
    
    print(f"\nè®­ç»ƒé›†: {len(S_train)} å¤©")
    if len(S_train) > 0:
        print(f"  èŒƒå›´: {S_train.index.min().date()} - {S_train.index.max().date()}")
    
    print(f"æµ‹è¯•é›†: {len(S_test)} å¤©")
    if len(S_test) > 0:
        print(f"  èŒƒå›´: {S_test.index.min().date()} - {S_test.index.max().date()}")
    
    # æ£€æŸ¥æ•°æ®é‡
    if len(S_train) < 100:
        print(f"\nâš ï¸ è®­ç»ƒé›†åªæœ‰ {len(S_train)} å¤©ï¼Œä¸è¶³100å¤©")
        print("å°è¯•ä½¿ç”¨å…¨éƒ¨æ•°æ®çš„å‰70%ä½œä¸ºè®­ç»ƒé›†...")
        
        # å¤‡é€‰æ–¹æ¡ˆï¼šæŒ‰æ¯”ä¾‹åˆ’åˆ†
        split_idx = int(len(S) * 0.7)
        S_train = S.iloc[:split_idx]
        S_test = S.iloc[split_idx:]
        index_train = index.iloc[:split_idx]
        index_test = index.iloc[split_idx:]
        
        print(f"\næ–°åˆ’åˆ†:")
        print(f"è®­ç»ƒé›†: {len(S_train)} å¤© ({S_train.index.min().date()} - {S_train.index.max().date()})")
        print(f"æµ‹è¯•é›†: {len(S_test)} å¤© ({S_test.index.min().date()} - {S_test.index.max().date()})")
    
    # 6. è®¡ç®—é˜ˆå€¼
    threshold = S_train.quantile(0.90)
    print(f"\né˜ˆå€¼ (90%åˆ†ä½): {threshold:.4f}")
    
    # 7. æµ‹è¯•ç­–ç•¥
    print("\n" + "="*60)
    print("ç­–ç•¥æµ‹è¯•ç»“æœ")
    print("="*60)
    
    train_results = test_strategy(S_train, index_train, threshold, HORIZON)
    test_results = test_strategy(S_test, index_test, threshold, HORIZON)
    
    print(f"\n{'é›†åˆ':<10} {'äº¤æ˜“æ¬¡æ•°':<10} {'èƒœç‡':<10} {'å¹³å‡æ”¶ç›Š':<12} {'ç´¯è®¡æ”¶ç›Š':<12}")
    print("-"*55)
    
    if train_results is not None and len(train_results) > 0:
        train_wr = train_results['win'].mean()
        train_ret = train_results['return'].mean()
        train_cum = train_results['return'].sum()
        print(f"{'è®­ç»ƒé›†':<10} {len(train_results):<10} {train_wr:<10.1%} {train_ret:<12.1%} {train_cum:<12.1%}")
    else:
        print(f"{'è®­ç»ƒé›†':<10} {'æ— ä¿¡å·':<10}")
    
    if test_results is not None and len(test_results) > 0:
        test_wr = test_results['win'].mean()
        test_ret = test_results['return'].mean()
        test_cum = test_results['return'].sum()
        print(f"{'æµ‹è¯•é›†':<10} {len(test_results):<10} {test_wr:<10.1%} {test_ret:<12.1%} {test_cum:<12.1%}")
        
        # ä¿å­˜ç»“æœ
        test_results.to_csv('emis_results_DAX.csv', index=False)
        print(f"\nç»“æœå·²ä¿å­˜: emis_results_DAX.csv")
        
        # ç»“è®º
        print("\n" + "="*60)
        if test_wr > 0.6:
            print("âœ… å¾·å›½å¸‚åœºéªŒè¯æˆåŠŸï¼")
        elif test_wr > 0.5:
            print("ğŸ”¶ å¾·å›½å¸‚åœºæ•ˆæœä¸€èˆ¬ï¼Œä¼˜äºéšæœº")
        else:
            print("âŒ å¾·å›½å¸‚åœºéªŒè¯å¤±è´¥")
        print("="*60)
        
    else:
        print(f"{'æµ‹è¯•é›†':<10} {'æ— ä¿¡å·':<10}")
    
    # 8. æ±‡æ€»ä¸‰ä¸ªå¸‚åœº
    print("\n" + "="*60)
    print("å…¨çƒéªŒè¯æ±‡æ€»ï¼ˆæ›´æ–°ç‰ˆï¼‰")
    print("="*60)
    
    print(f"\n{'å¸‚åœº':<20} {'æµ‹è¯•äº¤æ˜“':<10} {'èƒœç‡':<10} {'å¹³å‡æ”¶ç›Š':<12}")
    print("-"*55)
    print(f"{'ç¾å›½ S&P 500':<20} {'243':<10} {'81.5%':<10} {'5.1%':<12}")
    print(f"{'æ—¥æœ¬ Nikkei 225':<20} {'160':<10} {'90.6%':<10} {'5.8%':<12}")
    
    if test_results is not None and len(test_results) > 0:
        print(f"{'å¾·å›½ DAX':<20} {len(test_results):<10} {test_wr:<10.1%} {test_ret:<12.1%}")
        
        # è®¡ç®—ä¸‰å¸‚åœºå¹³å‡
        all_wr = [0.815, 0.906, test_wr]
        all_ret = [0.051, 0.058, test_ret]
        print("-"*55)
        print(f"{'å¹³å‡':<20} {'':<10} {np.mean(all_wr):<10.1%} {np.mean(all_ret):<12.1%}")
    
    return test_results

# ============================================
# è¿è¡Œ
# ============================================

if __name__ == "__main__":
    results = main()