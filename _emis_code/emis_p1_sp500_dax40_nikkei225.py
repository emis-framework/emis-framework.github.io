"""
EMIS P1 å…¨çƒéªŒè¯ï¼šç¾å›½ + æ¬§æ´² + äºšæ´²
"""

import numpy as np
import pandas as pd
import yfinance as yf
import time
import os
import warnings
warnings.filterwarnings('ignore')

# ============================================
# å‚æ•°è®¾ç½®
# ============================================

START_DATE = '2010-01-01'
TRAIN_END = '2020-01-01'
WINDOW = 60
HORIZON = 30

# ============================================
# ä¸‰ä¸ªå¸‚åœºçš„è‚¡ç¥¨æ± 
# ============================================

MARKETS = {
    'US': {
        'name': 'S&P 500 (ç¾å›½)',
        'index': '^GSPC',
        'tickers': [
            'AAPL', 'MSFT', 'GOOGL', 'AMZN', 'META',
            'NVDA', 'BRK-B', 'JPM', 'JNJ', 'V',
            'PG', 'UNH', 'HD', 'MA', 'DIS',
            'PYPL', 'VZ', 'ADBE', 'NFLX', 'CRM',
            'INTC', 'CMCSA', 'PFE', 'KO', 'PEP',
            'T', 'MRK', 'WMT', 'ABT', 'CVX',
            'XOM', 'BA', 'CSCO', 'WFC', 'C',
            'ORCL', 'ACN', 'COST', 'NKE', 'MCD',
            'DHR', 'NEE', 'LLY', 'TXN', 'QCOM',
            'LOW', 'UPS', 'BMY', 'AMGN', 'IBM'
        ]
    },
    'EU': {
        'name': 'DAX 40 (å¾·å›½)',
        'index': '^GDAXI',
        'tickers': [
            'SAP.DE', 'SIE.DE', 'ALV.DE', 'DTE.DE', 'BAS.DE',
            'BAYN.DE', 'MBG.DE', 'BMW.DE', 'MUV2.DE', 'ADS.DE',
            'AIR.DE', 'DPW.DE', 'DB1.DE', 'VOW3.DE', 'IFX.DE',
            'HEN3.DE', 'RWE.DE', 'EOAN.DE', 'FRE.DE', 'CON.DE',
            'BEI.DE', 'HEI.DE', 'MRK.DE', 'VNA.DE', 'FME.DE',
            'MTX.DE', 'SY1.DE', 'ENR.DE', 'ZAL.DE', 'PUM.DE'
        ]
    },
    'ASIA': {
        'name': 'Nikkei 225 (æ—¥æœ¬)',
        'index': '^N225',
        'tickers': [
            '7203.T', '6758.T', '9984.T', '6861.T', '8306.T',
            '9432.T', '6501.T', '7267.T', '4502.T', '6902.T',
            '7751.T', '8035.T', '6367.T', '4063.T', '6954.T',
            '7974.T', '8316.T', '9433.T', '6981.T', '4519.T',
            '8411.T', '6503.T', '7201.T', '2914.T', '3382.T',
            '4568.T', '6702.T', '8031.T', '9022.T', '6326.T'
        ]
    }
}

# ============================================
# æ•°æ®åŠ è½½å‡½æ•°
# ============================================

def load_market_data(market_key, force_download=False):
    """åŠ è½½æŸä¸ªå¸‚åœºçš„æ•°æ®"""
    market = MARKETS[market_key]
    
    stock_file = f'stocks_{market_key}.csv'
    index_file = f'index_{market_key}.csv'
    
    # åŠ è½½è‚¡ç¥¨æ•°æ®
    if os.path.exists(stock_file) and not force_download:
        print(f"ä»æœ¬åœ°åŠ è½½: {stock_file}")
        prices = pd.read_csv(stock_file, index_col=0, parse_dates=True)
    else:
        print(f"ä¸‹è½½ {market['name']} è‚¡ç¥¨...")
        all_data = []
        batch_size = 10
        
        for i in range(0, len(market['tickers']), batch_size):
            batch = market['tickers'][i:i+batch_size]
            print(f"  ä¸‹è½½ {i+1}-{min(i+batch_size, len(market['tickers']))}...")
            try:
                data = yf.download(batch, start=START_DATE, progress=False)
                if not data.empty:
                    if 'Close' in data.columns:
                        all_data.append(data['Close'])
                    elif isinstance(data.columns, pd.MultiIndex):
                        all_data.append(data['Close'])
                time.sleep(1)
            except Exception as e:
                print(f"    é”™è¯¯: {e}")
                time.sleep(3)
        
        if all_data:
            prices = pd.concat(all_data, axis=1) if len(all_data) > 1 else all_data[0]
            prices.to_csv(stock_file)
            print(f"  å·²ä¿å­˜: {stock_file}")
        else:
            return None, None
    
    # åŠ è½½æŒ‡æ•°æ•°æ®
    if os.path.exists(index_file) and not force_download:
        print(f"ä»æœ¬åœ°åŠ è½½: {index_file}")
        index = pd.read_csv(index_file, index_col=0, parse_dates=True).iloc[:, 0]
    else:
        print(f"ä¸‹è½½ {market['name']} æŒ‡æ•°...")
        time.sleep(2)
        try:
            data = yf.download(market['index'], start=START_DATE, progress=False)
            index = data['Close']
            if isinstance(index, pd.DataFrame):
                index = index.iloc[:, 0]
            index.to_csv(index_file)
            print(f"  å·²ä¿å­˜: {index_file}")
        except Exception as e:
            print(f"  é”™è¯¯: {e}")
            return prices, None
    
    # æ¸…ç†æ•°æ®
    if prices is not None:
        prices = prices.dropna(axis=1, how='all').ffill().dropna()
    
    return prices, index

# ============================================
# è®¡ç®—å‡½æ•°
# ============================================

def compute_returns(prices):
    return np.log(prices / prices.shift(1)).dropna()

def compute_entanglement_entropy(returns, window=60):
    S_list = []
    dates = []
    N = returns.shape[1]
    
    for t in range(window, len(returns)):
        window_returns = returns.iloc[t-window:t]
        Sigma = window_returns.corr().values
        Sigma = Sigma + np.eye(N) * 1e-6
        det_Sigma = np.linalg.det(Sigma)
        
        if det_Sigma > 0:
            S = -np.log(det_Sigma) / N
        else:
            S = np.nan
        
        S_list.append(S)
        dates.append(returns.index[t])
    
    return pd.Series(S_list, index=dates)

def test_strategy(S, index, threshold, horizon=30):
    """æµ‹è¯•ç­–ç•¥æ•ˆæœ"""
    results = []
    
    for t in range(len(S) - horizon):
        date = S.index[t]
        value = S.iloc[t]
        
        if value > threshold and date in index.index:
            idx = index.index.get_loc(date)
            if idx + horizon < len(index):
                ret = np.log(index.iloc[idx + horizon] / index.iloc[idx])
                results.append({
                    'date': date,
                    'S': value,
                    'return': ret,
                    'win': ret > 0
                })
    
    return pd.DataFrame(results) if results else None

# ============================================
# éªŒè¯å•ä¸ªå¸‚åœº
# ============================================

def validate_market(market_key):
    """éªŒè¯å•ä¸ªå¸‚åœº"""
    market = MARKETS[market_key]
    print(f"\n{'='*60}")
    print(f"éªŒè¯å¸‚åœº: {market['name']}")
    print('='*60)
    
    # åŠ è½½æ•°æ®
    prices, index = load_market_data(market_key)
    
    if prices is None or index is None:
        print("âŒ æ•°æ®åŠ è½½å¤±è´¥")
        return None
    
    if len(prices.columns) < 10:
        print(f"âŒ è‚¡ç¥¨æ•°é‡ä¸è¶³: {len(prices.columns)}")
        return None
    
    print(f"\næœ‰æ•ˆæ•°æ®: {len(prices.columns)} åªè‚¡ç¥¨, {len(prices)} å¤©")
    
    # è®¡ç®—çº ç¼ ç†µ
    print("è®¡ç®—çº ç¼ ç†µ...")
    returns = compute_returns(prices)
    S = compute_entanglement_entropy(returns, window=WINDOW)
    
    # ä¿å­˜
    S.to_csv(f'entropy_{market_key}.csv')
    
    print(f"çº ç¼ ç†µèŒƒå›´: [{S.min():.2f}, {S.max():.2f}]")
    
    # å¯¹é½æ—¶é—´
    common_idx = S.index.intersection(index.index)
    S = S.loc[common_idx]
    index = index.loc[common_idx]
    
    # æ ·æœ¬åˆ’åˆ†
    train_mask = S.index < TRAIN_END
    test_mask = S.index >= TRAIN_END
    
    S_train = S[train_mask]
    S_test = S[test_mask]
    index_train = index[train_mask]
    index_test = index[test_mask]
    
    print(f"\nè®­ç»ƒé›†: {len(S_train)} å¤©")
    print(f"æµ‹è¯•é›†: {len(S_test)} å¤©")
    
    if len(S_train) < 100 or len(S_test) < 100:
        print("âŒ æ•°æ®é‡ä¸è¶³")
        return None
    
    # è®¡ç®—é˜ˆå€¼
    threshold = S_train.quantile(0.90)
    print(f"é˜ˆå€¼ (90%åˆ†ä½): {threshold:.4f}")
    
    # è®­ç»ƒé›†æ•ˆæœ
    train_results = test_strategy(S_train, index_train, threshold, HORIZON)
    
    # æµ‹è¯•é›†æ•ˆæœ
    test_results = test_strategy(S_test, index_test, threshold, HORIZON)
    
    # æ±‡æ€»ç»“æœ
    result = {
        'market': market['name'],
        'n_stocks': len(prices.columns),
        'threshold': threshold,
        'train_n': len(train_results) if train_results is not None else 0,
        'train_wr': train_results['win'].mean() if train_results is not None and len(train_results) > 0 else 0,
        'train_ret': train_results['return'].mean() if train_results is not None and len(train_results) > 0 else 0,
        'test_n': len(test_results) if test_results is not None else 0,
        'test_wr': test_results['win'].mean() if test_results is not None and len(test_results) > 0 else 0,
        'test_ret': test_results['return'].mean() if test_results is not None and len(test_results) > 0 else 0,
    }
    
    # æ‰“å°ç»“æœ
    print(f"\n{'é›†åˆ':<10} {'äº¤æ˜“æ¬¡æ•°':<10} {'èƒœç‡':<10} {'å¹³å‡æ”¶ç›Š':<12}")
    print("-"*45)
    print(f"{'è®­ç»ƒé›†':<10} {result['train_n']:<10} {result['train_wr']:<10.1%} {result['train_ret']:<12.1%}")
    print(f"{'æµ‹è¯•é›†':<10} {result['test_n']:<10} {result['test_wr']:<10.1%} {result['test_ret']:<12.1%}")
    
    if result['test_wr'] > 0.6:
        print("\nâœ… æ ·æœ¬å¤–éªŒè¯æˆåŠŸï¼")
    elif result['test_wr'] > 0.5:
        print("\nğŸ”¶ æ ·æœ¬å¤–æ•ˆæœä¸€èˆ¬")
    else:
        print("\nâŒ æ ·æœ¬å¤–éªŒè¯å¤±è´¥")
    
    return result

# ============================================
# ä¸»ç¨‹åº
# ============================================

def main():
    print("="*60)
    print("EMIS P1 å…¨çƒéªŒè¯")
    print("="*60)
    print(f"æ•°æ®èŒƒå›´: {START_DATE} - ä»Šå¤©")
    print(f"è®­ç»ƒé›†æˆªæ­¢: {TRAIN_END}")
    print(f"éªŒè¯å¸‚åœº: ç¾å›½, å¾·å›½, æ—¥æœ¬")
    
    all_results = []
    
    for market_key in ['US', 'EU', 'ASIA']:
        result = validate_market(market_key)
        if result:
            all_results.append(result)
    
    # ============================================
    # æ±‡æ€»å¯¹æ¯”
    # ============================================
    
    print("\n" + "="*60)
    print("å…¨çƒéªŒè¯æ±‡æ€»")
    print("="*60)
    
    print(f"\n{'å¸‚åœº':<20} {'è‚¡ç¥¨æ•°':<8} {'æµ‹è¯•äº¤æ˜“':<10} {'èƒœç‡':<10} {'å¹³å‡æ”¶ç›Š':<12}")
    print("-"*60)
    
    for r in all_results:
        print(f"{r['market']:<20} {r['n_stocks']:<8} {r['test_n']:<10} {r['test_wr']:<10.1%} {r['test_ret']:<12.1%}")
    
    # è®¡ç®—å¹³å‡
    if len(all_results) > 0:
        avg_wr = np.mean([r['test_wr'] for r in all_results])
        avg_ret = np.mean([r['test_ret'] for r in all_results])
        
        print("-"*60)
        print(f"{'å¹³å‡':<20} {'':<8} {'':<10} {avg_wr:<10.1%} {avg_ret:<12.1%}")
    
    # æœ€ç»ˆç»“è®º
    print("\n" + "="*60)
    print("æœ€ç»ˆç»“è®º")
    print("="*60)
    
    success_count = sum(1 for r in all_results if r['test_wr'] > 0.6)
    
    if success_count == len(all_results):
        print("\nâœ… å…¨éƒ¨å¸‚åœºéªŒè¯æˆåŠŸï¼EMIS ç­–ç•¥å…·æœ‰å…¨çƒæœ‰æ•ˆæ€§")
    elif success_count > len(all_results) / 2:
        print(f"\nğŸ”¶ {success_count}/{len(all_results)} ä¸ªå¸‚åœºéªŒè¯æˆåŠŸ")
    else:
        print("\nâŒ å¤šæ•°å¸‚åœºéªŒè¯å¤±è´¥")
    
    # ä¿å­˜ç»“æœ
    results_df = pd.DataFrame(all_results)
    results_df.to_csv('global_validation_results.csv', index=False)
    print("\nç»“æœå·²ä¿å­˜: global_validation_results.csv")
    
    return all_results

# ============================================
# è¿è¡Œ
# ============================================

if __name__ == "__main__":
    results = main()